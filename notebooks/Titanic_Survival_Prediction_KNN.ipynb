{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "**Data preparation**\n",
    "\n",
    "- Handling missing values\n",
    "- Handling categorical features\n",
    "\n",
    "**Train & Tune Model**\n",
    "\n",
    "- Train model\n",
    "- Test accuracy\n",
    "- Tune model parameters\n",
    "\n",
    "**Make Prediction**\n",
    "- Update test data set\n",
    "- Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Data & Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "rf_tune = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the Titanic training data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "path = '../data/'\n",
    "url = path + 'train.csv'\n",
    "titanic = pd.read_csv(url, index_col='PassengerId')\n",
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn models expect that all values are **numeric** and **hold meaning**. Thus, missing values are not allowed by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xwhx\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# fill missing values for Age with the median age\n",
    "titanic.Age.fillna(titanic.Age.median(), inplace=True)\n",
    "\n",
    "# get average, std, and number of NaN values in titanic_df\n",
    "average_age_titanic   = titanic[\"Age\"].mean()\n",
    "std_age_titanic       = titanic[\"Age\"].std()\n",
    "count_nan_age_titanic = titanic[\"Age\"].isnull().sum()\n",
    "\n",
    "# generate random numbers between (mean - std) & (mean + std)\n",
    "rand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\n",
    "\n",
    "# fill NaN values in Age column with random values generated\n",
    "titanic[\"Age\"][np.isnan(titanic[\"Age\"])] = rand_1\n",
    "\n",
    "# convert from float to int\n",
    "titanic['Age'] = titanic['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing values for Embarked with the mode\n",
    "titanic.Embarked.fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the Titanic test data\n",
    "import pandas as pd\n",
    "path = '../data/'\n",
    "url = path + 'test.csv'\n",
    "titanic_test = pd.read_csv(url)\n",
    "titanic_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "titanic_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xwhx\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "titanic_test.Age.fillna(titanic_test.Age.median(), inplace=True)\n",
    "\n",
    "# get average, std, and number of NaN values in test_df\n",
    "average_age_test   = titanic_test[\"Age\"].mean()\n",
    "std_age_test       = titanic_test[\"Age\"].std()\n",
    "count_nan_age_test = titanic_test[\"Age\"].isnull().sum()\n",
    "\n",
    "# generate random numbers between (mean - std) & (mean + std)\n",
    "rand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n",
    "\n",
    "# fill NaN values in Age column with random values generated\n",
    "titanic_test[\"Age\"][np.isnan(titanic_test[\"Age\"])] = rand_2\n",
    "\n",
    "# convert from float to int\n",
    "titanic_test['Age'] = titanic_test['Age'].astype(int)\n",
    "\n",
    "titanic_test.Fare.fillna(titanic_test.Fare.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Handling categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding (0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and encode Female feature - Replaced this below with a more granular definition\n",
    "#titanic['Female'] = titanic.Sex.map({'male':0, 'female':1})\n",
    "#titanic_test['Female'] = titanic_test.Sex.map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "embarked_dummies = pd.get_dummies(titanic.Embarked, prefix='Embarked')\n",
    "embarked_dummies.drop(embarked_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic = pd.concat([titanic, embarked_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "embarked_dummies = pd.get_dummies(titanic_test.Embarked, prefix='Embarked')\n",
    "embarked_dummies.drop(embarked_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic_test = pd.concat([titanic_test, embarked_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "pclass_dummies = pd.get_dummies(titanic.Pclass, prefix='Pclass')\n",
    "pclass_dummies.drop(pclass_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic = pd.concat([titanic, pclass_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "pclass_dummies = pd.get_dummies(titanic_test.Pclass, prefix='Pclass')\n",
    "pclass_dummies.drop(pclass_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic_test = pd.concat([titanic_test, pclass_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine Sibling and Parent Columns\n",
    "titanic['Family'] =  titanic[\"Parch\"] + titanic[\"SibSp\"]\n",
    "titanic['Family'].loc[titanic['Family'] > 0] = 1\n",
    "titanic['Family'].loc[titanic['Family'] == 0] = 0\n",
    "\n",
    "# This apporach did not improve the accuracy score\n",
    "#titanic['FamilySize'] =  titanic[\"Parch\"] + titanic[\"SibSp\"]\n",
    "#titanic.loc[titanic.FamilySize==1,'FamilyLabel'] = 'Single'\n",
    "#titanic.loc[titanic.FamilySize==2,'FamilyLabel'] = 'Couple'\n",
    "#titanic.loc[(titanic.FamilySize>2)&(titanic.FamilySize<=4),'FamilyLabel'] = 'Small'\n",
    "#titanic.loc[titanic.FamilySize>4,'FamilyLabel'] = 'Big'\n",
    "\n",
    "titanic_test['Family'] =  titanic_test[\"Parch\"] + titanic_test[\"SibSp\"]\n",
    "titanic_test['Family'].loc[titanic_test['Family'] > 0] = 1\n",
    "titanic_test['Family'].loc[titanic_test['Family'] == 0] = 0\n",
    "\n",
    "#titanic_test['FamilySize'] =  titanic_test[\"Parch\"] + titanic_test[\"SibSp\"]\n",
    "#titanic_test.loc[titanic_test.FamilySize==1,'FamilyLabel'] = 'Single'\n",
    "#titanic_test.loc[titanic_test.FamilySize==2,'FamilyLabel'] = 'Couple'\n",
    "#titanic_test.loc[(titanic_test.FamilySize>2)&(titanic_test.FamilySize<=4),'FamilyLabel'] = 'Small'\n",
    "#titanic_test.loc[titanic_test.FamilySize>4,'FamilyLabel'] = 'Big'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for FamilyLabel\n",
    "#familylabel_dummies = pd.get_dummies(titanic.FamilyLabel, prefix='FamilyLabel')\n",
    "#familylabel_dummies.drop(familylabel_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "#titanic = pd.concat([titanic, familylabel_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for FamilyLabel\n",
    "#familylabel_dummies = pd.get_dummies(titanic_test.FamilyLabel, prefix='FamilyLabel')\n",
    "#familylabel_dummies.drop(familylabel_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "#titanic_test = pd.concat([titanic_test, familylabel_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Children have a high rate of survival regardless of sex, so treat them as separate\n",
    "def get_person(passenger):\n",
    "    age,sex = passenger\n",
    "    return 'child' if age < 16 else sex\n",
    "    \n",
    "titanic['Person'] = titanic[['Age','Sex']].apply(get_person,axis=1)\n",
    "titanic_test['Person']    = titanic_test[['Age','Sex']].apply(get_person,axis=1)\n",
    "\n",
    "# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\n",
    "person_dummies_titanic  = pd.get_dummies(titanic['Person'])\n",
    "person_dummies_titanic.columns = ['Child','Female','Male']\n",
    "person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "person_dummies_test  = pd.get_dummies(titanic_test['Person'])\n",
    "person_dummies_test.columns = ['Child','Female','Male']\n",
    "person_dummies_test.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "titanic = pd.concat([titanic, person_dummies_titanic], axis=1)\n",
    "titanic_test = pd.concat([titanic_test, person_dummies_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.drop(\"Cabin\",axis=1,inplace=True)\n",
    "titanic.drop(\"Name\",axis=1,inplace=True)\n",
    "titanic.drop(\"Sex\",axis=1,inplace=True)\n",
    "titanic.drop(\"Ticket\",axis=1,inplace=True)\n",
    "titanic.drop(\"Embarked\",axis=1,inplace=True)\n",
    "titanic.drop(\"Pclass\",axis=1,inplace=True)\n",
    "titanic.drop(\"Parch\",axis=1,inplace=True)\n",
    "titanic.drop(\"SibSp\",axis=1,inplace=True)\n",
    "#titanic.drop(\"FamilySize\",axis=1,inplace=True)\n",
    "#titanic.drop(\"FamilyLabel\",axis=1,inplace=True)\n",
    "titanic.drop(\"Person\",axis=1,inplace=True)\n",
    "\n",
    "\n",
    "titanic_test.drop(\"Cabin\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Name\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Sex\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Ticket\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Embarked\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Pclass\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Parch\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"SibSp\",axis=1,inplace=True)\n",
    "#titanic_test.drop(\"FamilySize\",axis=1,inplace=True)\n",
    "#titanic_test.drop(\"FamilyLabel\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Person\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 10 columns):\n",
      "Survived      891 non-null int64\n",
      "Age           891 non-null int32\n",
      "Fare          891 non-null float64\n",
      "Embarked_Q    891 non-null float64\n",
      "Embarked_S    891 non-null float64\n",
      "Pclass_2      891 non-null float64\n",
      "Pclass_3      891 non-null float64\n",
      "Family        891 non-null int64\n",
      "Child         891 non-null float64\n",
      "Female        891 non-null float64\n",
      "dtypes: float64(7), int32(1), int64(2)\n",
      "memory usage: 73.1 KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Age            418 non-null int32\n",
      "Fare           418 non-null float64\n",
      "Embarked_Q     418 non-null float64\n",
      "Embarked_S     418 non-null float64\n",
      "Pclass_2       418 non-null float64\n",
      "Pclass_3       418 non-null float64\n",
      "Family         418 non-null int64\n",
      "Child          418 non-null float64\n",
      "Female         418 non-null float64\n",
      "dtypes: float64(7), int32(1), int64(2)\n",
      "memory usage: 31.1 KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Train and Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978675645342\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define training and testing sets\n",
    "\n",
    "X_train = titanic.drop(\"Survived\",axis=1)\n",
    "y_train = titanic[\"Survived\"]\n",
    "X_test  = titanic_test.drop(\"PassengerId\",axis=1).copy()\n",
    "\n",
    "# import KNN class we need from scikit-learnQ\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate the estimator \n",
    "knn = KNeighborsClassifier(n_neighbors=2, weights='distance') # Tune these parameters!\n",
    "\n",
    "# run a knn.fit on the data to build the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "titanic['y_pred_class_knn']=knn.predict(X_train)\n",
    "\n",
    "# Test the accuracy\n",
    "print knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the n_estimators parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if rf_tune == True:\n",
    "    # list of values to try for n_estimators\n",
    "    estimator_range = range(10, 310, 10)\n",
    "\n",
    "    # list to store the average RMSE for each value of n_estimators\n",
    "    RMSE_scores = []\n",
    "\n",
    "    # use 5-fold cross-validation with each value of n_estimators (WARNING: SLOW!)\n",
    "    for estimator in estimator_range:\n",
    "        rfclsf = RandomForestClassifier(n_estimators=estimator, random_state=1)\n",
    "        MSE_scores = cross_val_score(rfreg, X_train, y_train, cv=5, scoring='mean_squared_error')\n",
    "        RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if rf_tune == True:\n",
    "    # plot n_estimators (x-axis) versus RMSE (y-axis)\n",
    "    plt.plot(estimator_range, RMSE_scores)\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if rf_tune == True:\n",
    "    print zip(estimator_range,RMSE_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the max_features parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if rf_tune == True:\n",
    "    # list of values to try for max_features\n",
    "    feature_range = range(1, len(X_train.columns)+1)\n",
    "\n",
    "    # list to store the average RMSE for each value of max_features\n",
    "    RMSE_scores = []\n",
    "\n",
    "    # use 10-fold cross-validation with each value of max_features (WARNING: SLOW!)\n",
    "    for feature in feature_range:\n",
    "        rfclsf = RandomForestClassifier(n_estimators=200, max_features=feature, random_state=1)\n",
    "        MSE_scores = cross_val_score(rfclsf, X_train, y_train, cv=10, scoring='mean_squared_error')\n",
    "        RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if rf_tune == True:\n",
    "    # plot max_features (x-axis) versus RMSE (y-axis)\n",
    "    plt.plot(feature_range, RMSE_scores)\n",
    "    plt.xlabel('max_features')\n",
    "    plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if rf_tune == True:\n",
    "    # show the best RMSE and the corresponding max_features\n",
    "    sorted(zip(RMSE_scores, feature_range))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=7, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=70, n_jobs=1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_features=7 is best and n_estimators=70 is sufficiently large\n",
    "rfclsf = RandomForestClassifier(n_estimators=70, max_features=7, oob_score=True, random_state=1)\n",
    "rfclsf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.302867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Female</td>\n",
       "      <td>0.254949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.249424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.086333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Child</td>\n",
       "      <td>0.031565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.022860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Family</td>\n",
       "      <td>0.020793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.019336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.011872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "1        Fare    0.302867\n",
       "8      Female    0.254949\n",
       "0         Age    0.249424\n",
       "5    Pclass_3    0.086333\n",
       "7       Child    0.031565\n",
       "3  Embarked_S    0.022860\n",
       "6      Family    0.020793\n",
       "4    Pclass_2    0.019336\n",
       "2  Embarked_Q    0.011872"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute feature importances\n",
    "pd.DataFrame({'feature':X_train.columns, 'importance':rfclsf.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81930415263748602"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the out-of-bag R-squared score\n",
    "rfclsf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic['y_pred_class_rfclsf']=rfclsf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8630751964085297"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "titanic['y_pred_class_svc'] = svc.predict(X_train)\n",
    "\n",
    "svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78114478114478114"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "\n",
    "titanic['y_pred_class_gaussian'] = gaussian.predict(X_train)\n",
    "\n",
    "gaussian.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80471380471380471"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "titanic['y_pred_class_logreg'] = logreg.predict(X_train)\n",
    "\n",
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934904601571\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "titanic['y_pred_class_ensemble'] = ((titanic['y_pred_class_logreg'] + titanic['y_pred_class_gaussian'] + \n",
    "    titanic['y_pred_class_svc'] + titanic['y_pred_class_rfclsf'] + titanic['y_pred_class_knn'])/5).round(0).astype(int)\n",
    "print metrics.accuracy_score(titanic.Survived, titanic.y_pred_class_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "url = path + 'train_ensemble.csv'\n",
    "#titanic.index = titanic.PassengerId\n",
    "titanic.to_csv(columns = ['Survived', 'y_pred_class_ensemble', 'y_pred_class_logreg', 'y_pred_class_gaussian', 'y_pred_class_svc', \n",
    "                               'y_pred_class_rfclsf', 'y_pred_class_knn'], path_or_buf = url, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Make Predictions\n",
    "\n",
    "## Update Test Dataset & Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test['y_pred_class_knn']=knn.predict(X_test)\n",
    "titanic_test['y_pred_class_logreg']=logreg.predict(X_test)\n",
    "titanic_test['y_pred_class_gaussian']=gaussian.predict(X_test)\n",
    "titanic_test['y_pred_class_svc']=svc.predict(X_test)\n",
    "titanic_test['y_pred_class_rfclsf']=rfclsf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test['y_pred_class_ensemble'] = ((titanic_test['y_pred_class_logreg'] + titanic_test['y_pred_class_gaussian'] + \n",
    "    titanic_test['y_pred_class_svc'] + titanic_test['y_pred_class_rfclsf'] + titanic_test['y_pred_class_knn'])/5).round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make predictions for testing set\n",
    "titanic_test['Survived'] = titanic_test['y_pred_class_ensemble']\n",
    "\n",
    "path = '../data/'\n",
    "url = path + 'submit_ensemble_v1.csv'\n",
    "titanic_test.index = titanic_test.PassengerId\n",
    "titanic_test.to_csv(columns = ['Survived'], path_or_buf = url, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: Survived, dtype: float64\n",
      "0    0.643541\n",
      "1    0.356459\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print titanic.Survived.value_counts() / titanic.Survived.count()\n",
    "print titanic_test.Survived.value_counts() / titanic_test.Survived.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 17)"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "my_file = 'submit_ensemble_v1.csv'\n",
    "comp_file = 'submit_randomforest_v5.csv' # Downloaded this file from Kaggle as a comparison.\n",
    "\n",
    "url = path + my_file\n",
    "my_df = pd.read_csv(url, index_col='PassengerId')\n",
    "\n",
    "url = path + comp_file\n",
    "comp_df = pd.read_csv(url, index_col='PassengerId')\n",
    "\n",
    "joined_df = pd.concat([my_df, comp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mine</th>\n",
       "      <th>Compare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mine  Compare\n",
       "PassengerId               \n",
       "892             0        0\n",
       "893             0        0\n",
       "894             0        0\n",
       "895             0        1\n",
       "896             0        0"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.columns=['Mine', 'Compare']\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mine       46\n",
       "Compare    46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df[joined_df.Mine != joined_df.Compare].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mine</th>\n",
       "      <th>Compare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mine  Compare\n",
       "PassengerId               \n",
       "895             0        1\n",
       "898             1        0\n",
       "909             0        1\n",
       "919             0        1\n",
       "920             0        1\n",
       "924             0        1\n",
       "927             0        1\n",
       "933             0        1\n",
       "941             0        1\n",
       "967             1        0\n",
       "973             1        0\n",
       "979             0        1\n",
       "982             1        0\n",
       "990             0        1\n",
       "1000            0        1\n",
       "1005            1        0\n",
       "1022            0        1\n",
       "1036            0        1\n",
       "1040            0        1\n",
       "1049            0        1\n",
       "1050            0        1\n",
       "1051            1        0\n",
       "1055            0        1\n",
       "1073            1        0\n",
       "1079            0        1\n",
       "1094            1        0\n",
       "1109            1        0\n",
       "1115            0        1\n",
       "1126            1        0\n",
       "1128            1        0\n",
       "1129            0        1\n",
       "1134            1        0\n",
       "1144            1        0\n",
       "1200            1        0\n",
       "1203            0        1\n",
       "1208            1        0\n",
       "1225            1        0\n",
       "1228            0        1\n",
       "1237            0        1\n",
       "1255            0        1\n",
       "1259            1        0\n",
       "1261            0        1\n",
       "1268            1        0\n",
       "1275            1        0\n",
       "1297            0        1\n",
       "1299            1        0"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df[joined_df.Mine != joined_df.Compare]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
