{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "**Data preparation**\n",
    "\n",
    "- Handling missing values\n",
    "- Handling categorical features\n",
    "\n",
    "**Train & Tune Model**\n",
    "\n",
    "- Train model\n",
    "- Test accuracy\n",
    "- Tune model parameters\n",
    "\n",
    "**Make Prediction**\n",
    "- Update test data set\n",
    "- Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Data & Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "rf_tune = False\n",
    "knn_tune = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the Titanic training data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "path = '../data/'\n",
    "url = path + 'train.csv'\n",
    "titanic = pd.read_csv(url, index_col='PassengerId')\n",
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn models expect that all values are **numeric** and **hold meaning**. Thus, missing values are not allowed by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xwhx\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# fill missing values for Age with the median age\n",
    "titanic.Age.fillna(titanic.Age.median(), inplace=True)\n",
    "\n",
    "# get average, std, and number of NaN values in titanic_df\n",
    "average_age_titanic   = titanic[\"Age\"].mean()\n",
    "std_age_titanic       = titanic[\"Age\"].std()\n",
    "count_nan_age_titanic = titanic[\"Age\"].isnull().sum()\n",
    "\n",
    "# generate random numbers between (mean - std) & (mean + std)\n",
    "rand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\n",
    "\n",
    "# fill NaN values in Age column with random values generated\n",
    "titanic[\"Age\"][np.isnan(titanic[\"Age\"])] = rand_1\n",
    "\n",
    "# convert from float to int\n",
    "titanic['Age'] = titanic['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing values for Embarked with the mode\n",
    "titanic.Embarked.fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the Titanic test data\n",
    "import pandas as pd\n",
    "path = '../data/'\n",
    "url = path + 'test.csv'\n",
    "titanic_test = pd.read_csv(url)\n",
    "titanic_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "titanic_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xwhx\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "titanic_test.Age.fillna(titanic_test.Age.median(), inplace=True)\n",
    "\n",
    "# get average, std, and number of NaN values in test_df\n",
    "average_age_test   = titanic_test[\"Age\"].mean()\n",
    "std_age_test       = titanic_test[\"Age\"].std()\n",
    "count_nan_age_test = titanic_test[\"Age\"].isnull().sum()\n",
    "\n",
    "# generate random numbers between (mean - std) & (mean + std)\n",
    "rand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n",
    "\n",
    "# fill NaN values in Age column with random values generated\n",
    "titanic_test[\"Age\"][np.isnan(titanic_test[\"Age\"])] = rand_2\n",
    "\n",
    "# convert from float to int\n",
    "titanic_test['Age'] = titanic_test['Age'].astype(int)\n",
    "\n",
    "titanic_test.Fare.fillna(titanic_test.Fare.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Handling categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding (0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and encode Female feature - Replaced this below with a more granular definition\n",
    "#titanic['Female'] = titanic.Sex.map({'male':0, 'female':1})\n",
    "#titanic_test['Female'] = titanic_test.Sex.map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "embarked_dummies = pd.get_dummies(titanic.Embarked, prefix='Embarked')\n",
    "embarked_dummies.drop(embarked_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic = pd.concat([titanic, embarked_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "embarked_dummies = pd.get_dummies(titanic_test.Embarked, prefix='Embarked')\n",
    "embarked_dummies.drop(embarked_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic_test = pd.concat([titanic_test, embarked_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "pclass_dummies = pd.get_dummies(titanic.Pclass, prefix='Pclass')\n",
    "pclass_dummies.drop(pclass_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic = pd.concat([titanic, pclass_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "pclass_dummies = pd.get_dummies(titanic_test.Pclass, prefix='Pclass')\n",
    "pclass_dummies.drop(pclass_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic_test = pd.concat([titanic_test, pclass_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine Sibling and Parent Columns\n",
    "titanic['Family'] =  titanic[\"Parch\"] + titanic[\"SibSp\"]\n",
    "titanic['Family'].loc[titanic['Family'] > 0] = 1\n",
    "titanic['Family'].loc[titanic['Family'] == 0] = 0\n",
    "\n",
    "# This apporach did not improve the accuracy score\n",
    "#titanic['FamilySize'] =  titanic[\"Parch\"] + titanic[\"SibSp\"]\n",
    "#titanic.loc[titanic.FamilySize==1,'FamilyLabel'] = 'Single'\n",
    "#titanic.loc[titanic.FamilySize==2,'FamilyLabel'] = 'Couple'\n",
    "#titanic.loc[(titanic.FamilySize>2)&(titanic.FamilySize<=4),'FamilyLabel'] = 'Small'\n",
    "#titanic.loc[titanic.FamilySize>4,'FamilyLabel'] = 'Big'\n",
    "\n",
    "titanic_test['Family'] =  titanic_test[\"Parch\"] + titanic_test[\"SibSp\"]\n",
    "titanic_test['Family'].loc[titanic_test['Family'] > 0] = 1\n",
    "titanic_test['Family'].loc[titanic_test['Family'] == 0] = 0\n",
    "\n",
    "#titanic_test['FamilySize'] =  titanic_test[\"Parch\"] + titanic_test[\"SibSp\"]\n",
    "#titanic_test.loc[titanic_test.FamilySize==1,'FamilyLabel'] = 'Single'\n",
    "#titanic_test.loc[titanic_test.FamilySize==2,'FamilyLabel'] = 'Couple'\n",
    "#titanic_test.loc[(titanic_test.FamilySize>2)&(titanic_test.FamilySize<=4),'FamilyLabel'] = 'Small'\n",
    "#titanic_test.loc[titanic_test.FamilySize>4,'FamilyLabel'] = 'Big'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for FamilyLabel\n",
    "#familylabel_dummies = pd.get_dummies(titanic.FamilyLabel, prefix='FamilyLabel')\n",
    "#familylabel_dummies.drop(familylabel_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "#titanic = pd.concat([titanic, familylabel_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for FamilyLabel\n",
    "#familylabel_dummies = pd.get_dummies(titanic_test.FamilyLabel, prefix='FamilyLabel')\n",
    "#familylabel_dummies.drop(familylabel_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "#titanic_test = pd.concat([titanic_test, familylabel_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Children have a high rate of survival regardless of sex, so treat them as separate\n",
    "def get_person(passenger):\n",
    "    age,sex = passenger\n",
    "    return 'child' if age < 16 else sex\n",
    "    \n",
    "titanic['Person'] = titanic[['Age','Sex']].apply(get_person,axis=1)\n",
    "titanic_test['Person']    = titanic_test[['Age','Sex']].apply(get_person,axis=1)\n",
    "\n",
    "# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\n",
    "person_dummies_titanic  = pd.get_dummies(titanic['Person'])\n",
    "person_dummies_titanic.columns = ['Child','Female','Male']\n",
    "person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "person_dummies_test  = pd.get_dummies(titanic_test['Person'])\n",
    "person_dummies_test.columns = ['Child','Female','Male']\n",
    "person_dummies_test.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "titanic = pd.concat([titanic, person_dummies_titanic], axis=1)\n",
    "titanic_test = pd.concat([titanic_test, person_dummies_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.drop(\"Cabin\",axis=1,inplace=True)\n",
    "titanic.drop(\"Name\",axis=1,inplace=True)\n",
    "titanic.drop(\"Sex\",axis=1,inplace=True)\n",
    "titanic.drop(\"Ticket\",axis=1,inplace=True)\n",
    "titanic.drop(\"Embarked\",axis=1,inplace=True)\n",
    "titanic.drop(\"Pclass\",axis=1,inplace=True)\n",
    "titanic.drop(\"Parch\",axis=1,inplace=True)\n",
    "titanic.drop(\"SibSp\",axis=1,inplace=True)\n",
    "#titanic.drop(\"FamilySize\",axis=1,inplace=True)\n",
    "#titanic.drop(\"FamilyLabel\",axis=1,inplace=True)\n",
    "titanic.drop(\"Person\",axis=1,inplace=True)\n",
    "\n",
    "\n",
    "titanic_test.drop(\"Cabin\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Name\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Sex\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Ticket\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Embarked\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Pclass\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Parch\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"SibSp\",axis=1,inplace=True)\n",
    "#titanic_test.drop(\"FamilySize\",axis=1,inplace=True)\n",
    "#titanic_test.drop(\"FamilyLabel\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Person\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.Embarked_Q = titanic.Embarked_Q.astype(int)\n",
    "titanic.Embarked_S = titanic.Embarked_S.astype(int)\n",
    "titanic.Pclass_2 = titanic.Pclass_2.astype(int)\n",
    "titanic.Pclass_3 = titanic.Pclass_3.astype(int)\n",
    "titanic.Family = titanic.Family.astype(int)\n",
    "titanic.Child = titanic.Child.astype(int)\n",
    "titanic.Female = titanic.Female.astype(int)\n",
    "titanic.Survived = titanic.Survived.astype(int)\n",
    "\n",
    "titanic_test.Embarked_Q = titanic_test.Embarked_Q.astype(int)\n",
    "titanic_test.Embarked_S = titanic_test.Embarked_S.astype(int)\n",
    "titanic_test.Pclass_2 = titanic_test.Pclass_2.astype(int)\n",
    "titanic_test.Pclass_3 = titanic_test.Pclass_3.astype(int)\n",
    "titanic_test.Family = titanic_test.Family.astype(int)\n",
    "titanic_test.Child = titanic_test.Child.astype(int)\n",
    "titanic_test.Female = titanic_test.Female.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 10 columns):\n",
      "Survived      891 non-null int32\n",
      "Age           891 non-null int32\n",
      "Fare          891 non-null float64\n",
      "Embarked_Q    891 non-null int32\n",
      "Embarked_S    891 non-null int32\n",
      "Pclass_2      891 non-null int32\n",
      "Pclass_3      891 non-null int32\n",
      "Family        891 non-null int32\n",
      "Child         891 non-null int32\n",
      "Female        891 non-null int32\n",
      "dtypes: float64(1), int32(9)\n",
      "memory usage: 45.2 KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Age            418 non-null int32\n",
      "Fare           418 non-null float64\n",
      "Embarked_Q     418 non-null int32\n",
      "Embarked_S     418 non-null int32\n",
      "Pclass_2       418 non-null int32\n",
      "Pclass_3       418 non-null int32\n",
      "Family         418 non-null int32\n",
      "Child          418 non-null int32\n",
      "Female         418 non-null int32\n",
      "dtypes: float64(1), int32(8), int64(1)\n",
      "memory usage: 19.7 KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 9 columns):\n",
      "Age           418 non-null int32\n",
      "Fare          418 non-null float64\n",
      "Embarked_Q    418 non-null int32\n",
      "Embarked_S    418 non-null int32\n",
      "Pclass_2      418 non-null int32\n",
      "Pclass_3      418 non-null int32\n",
      "Family        418 non-null int32\n",
      "Child         418 non-null int32\n",
      "Female        418 non-null int32\n",
      "dtypes: float64(1), int32(8)\n",
      "memory usage: 19.6 KB\n",
      "None\n",
      " ----------------------- \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 10 columns):\n",
      "Survived      891 non-null int32\n",
      "Age           891 non-null int32\n",
      "Fare          891 non-null float64\n",
      "Embarked_Q    891 non-null int32\n",
      "Embarked_S    891 non-null int32\n",
      "Pclass_2      891 non-null int32\n",
      "Pclass_3      891 non-null int32\n",
      "Family        891 non-null int32\n",
      "Child         891 non-null int32\n",
      "Female        891 non-null int32\n",
      "dtypes: float64(1), int32(9)\n",
      "memory usage: 45.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_df = titanic.copy()\n",
    "test_df = titanic_test.copy()\n",
    "\n",
    "test_df.index = test_df.PassengerId\n",
    "test_df.drop('PassengerId', axis=1, inplace=True)\n",
    "print test_df.info()\n",
    "print ' ----------------------- '\n",
    "print train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "path = '../data/'\n",
    "url = path + 'merged_train_and_test.csv'\n",
    "merged_df.to_csv(columns = merged_df.columns, path_or_buf = url, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Train and Tune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training and Test dataframes\n",
    "### Start with the full list of features and evaluate them with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = titanic.drop(\"Survived\",axis=1)\n",
    "y_train = titanic[\"Survived\"]\n",
    "X_test  = titanic_test.drop(\"PassengerId\",axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors Classifier\n",
    "## Tune n_neighbors parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731903018954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# search for an optimal value of K for KNN\n",
    "def knn_nestimators_tuning():\n",
    "    knn = KNeighborsClassifier()\n",
    "    k_range = range(1, 51)\n",
    "    weight_options = ['uniform', 'distance']\n",
    "    param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    print grid.best_score_\n",
    "    print grid.best_params_\n",
    "    return  grid.best_estimator_\n",
    "    \n",
    "if knn_tune == True:\n",
    "    knn = knn_nestimators_tuning()\n",
    "else:\n",
    "    knn = KNeighborsClassifier(n_neighbors=33, weights='distance')\n",
    "    print cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Evaluation\n",
    "### Start with the feature that have the highest correlation and build up from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Evaluation - Started with Fare, Age and Female and added features until the cross validation score stopped increasing\n",
    "# manually ran this step with different feature combinations\n",
    "feature_cols_knn = ['Fare',  'Age', 'Female', 'Pclass_3', 'Child', 'Embarked_S', 'Family']\n",
    "X_train = titanic[feature_cols_knn]\n",
    "X_test = titanic_test[feature_cols_knn]\n",
    "\n",
    "if knn_tune == True:\n",
    "    # recalculate accuracy\n",
    "    print cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "    # repeat nestimators tuning to see if anything has changed since downselecting features\n",
    "    knn = knn_nestimators_tuning()\n",
    "else:\n",
    "    knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979797979798\n"
     ]
    }
   ],
   "source": [
    "# run a knn.fit on the data to build the model\n",
    "#knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class_knn = knn.predict(X_train)\n",
    "\n",
    "# Test the accuracy\n",
    "print knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with the Full List of Features and Edit down from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = titanic.drop(\"Survived\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the n_estimators and max_features parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821656735898\n",
      "0.817059483726\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rfclsf_nestimators_tuning():\n",
    "    rfclsf = RandomForestClassifier(random_state=1)\n",
    "    estimator_range = range(10, 310, 10)\n",
    "    feature_range = range(1, len(X_train.columns)+1)\n",
    "    param_grid = dict(n_estimators=estimator_range, max_features=feature_range)\n",
    "    grid = GridSearchCV(rfclsf, param_grid, cv=10, scoring='mean_squared_error')\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print grid.best_score_\n",
    "    print grid.best_params_\n",
    "    return  grid.best_estimator_\n",
    "\n",
    "if rf_tune == True:\n",
    "    rfclsf = rfclsf_nestimators_tuning()\n",
    "else:\n",
    "    rfclsf = RandomForestClassifier(n_estimators=260, max_features=6, oob_score=True, random_state=1)\n",
    "    print cross_val_score(rfclsf, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "    # compute the out-of-bag R-squared score\n",
    "    rfclsf.fit(X_train, y_train)\n",
    "    print rfclsf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Age', u'Fare', u'Embarked_Q', u'Embarked_S', u'Pclass_2', u'Pclass_3',\n",
       "       u'Family', u'Child', u'Female'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.301945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.261031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Female</td>\n",
       "      <td>0.253307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.083178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Child</td>\n",
       "      <td>0.025755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.022752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Family</td>\n",
       "      <td>0.021671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.019157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.011204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "1        Fare    0.301945\n",
       "0         Age    0.261031\n",
       "8      Female    0.253307\n",
       "5    Pclass_3    0.083178\n",
       "7       Child    0.025755\n",
       "3  Embarked_S    0.022752\n",
       "6      Family    0.021671\n",
       "4    Pclass_2    0.019157\n",
       "2  Embarked_Q    0.011204"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute feature importances\n",
    "pd.DataFrame({'feature':X_train.columns, 'importance':rfclsf.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_class_rfclsf = rfclsf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8630751964085297"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class_svc = svc.predict(X_train)\n",
    "\n",
    "svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78114478114478114"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class_gaussian = gaussian.predict(X_train)\n",
    "\n",
    "gaussian.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80471380471380471"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class_logreg = logreg.predict(X_train)\n",
    "\n",
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763187429854\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred_class_ensemble = ((y_pred_class_logreg + y_pred_class_gaussian + y_pred_class_svc + y_pred_class_rfclsf\n",
    "                                     + y_pred_class_knn)/5).round(0).astype(int)\n",
    "print metrics.accuracy_score(titanic.Survived, y_pred_class_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "url = path + 'train_ensemble.csv'\n",
    "ensemble_df = pd.DataFrame({'PassengerId' : titanic.index,\n",
    "                        'Survived' : y_train, \n",
    "                        'y_pred_class_ensemble' : y_pred_class_ensemble,\n",
    "                        'y_pred_class_logreg' : y_pred_class_logreg,\n",
    "                        'y_pred_class_gaussian' : y_pred_class_gaussian, \n",
    "                        'y_pred_class_svc' : y_pred_class_svc,\n",
    "                        'y_pred_class_rfclsf' : y_pred_class_rfclsf, \n",
    "                        'y_pred_class_knn' : y_pred_class_knn}).set_index('PassengerId')\n",
    "#titanic.index = titanic.PassengerId\n",
    "ensemble_df.to_csv(columns = ensemble_df.columns, path_or_buf = url, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Make Predictions\n",
    "\n",
    "## Update Test Dataset & Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 10)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "titanic_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#titanic_test['y_pred_class_knn']=knn.predict(X_test)\n",
    "#titanic_test['y_pred_class_logreg']=logreg.predict(X_test)\n",
    "#titanic_test['y_pred_class_gaussian']=gaussian.predict(X_test)\n",
    "#titanic_test['y_pred_class_svc']=svc.predict(X_test)\n",
    "titanic_test['y_pred_class_rfclsf']=rfclsf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test['y_pred_class_ensemble'] = ((titanic_test['y_pred_class_logreg'] + titanic_test['y_pred_class_gaussian'] + \n",
    "    titanic_test['y_pred_class_svc'] + titanic_test['y_pred_class_rfclsf'] + titanic_test['y_pred_class_knn'])/5).round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make predictions for testing set\n",
    "titanic_test['Survived'] = titanic_test['y_pred_class_ensemble']\n",
    "\n",
    "path = '../data/'\n",
    "url = path + 'submit_ensemble_v1.csv'\n",
    "titanic_test.index = titanic_test.PassengerId\n",
    "titanic_test.to_csv(columns = ['Survived'], path_or_buf = url, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions for testing set\n",
    "titanic_test['Survived'] = titanic_test['y_pred_class_rfclsf']\n",
    "\n",
    "path = '../data/'\n",
    "url = path + 'submit_randomforest_v6.csv'\n",
    "titanic_test.index = titanic_test.PassengerId\n",
    "titanic_test.to_csv(columns = ['Survived'], path_or_buf = url, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: Survived, dtype: float64\n",
      "0    0.636364\n",
      "1    0.363636\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print titanic.Survived.value_counts() / titanic.Survived.count()\n",
    "print titanic_test.Survived.value_counts() / titanic_test.Survived.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 12)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "my_file = 'OmarElGabry.csv'\n",
    "comp_file = 'submit_randomforest_v6.csv' # Downloaded this file from Kaggle as a comparison.\n",
    "\n",
    "url = path + my_file\n",
    "my_df = pd.read_csv(url, index_col='PassengerId')\n",
    "\n",
    "url = path + comp_file\n",
    "comp_df = pd.read_csv(url, index_col='PassengerId')\n",
    "\n",
    "joined_df = pd.concat([my_df, comp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mine</th>\n",
       "      <th>Compare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mine  Compare\n",
       "PassengerId               \n",
       "892             0        0\n",
       "893             0        0\n",
       "894             0        0\n",
       "895             1        1\n",
       "896             0        0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.columns=['Mine', 'Compare']\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mine       44\n",
       "Compare    44\n",
       "dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df[joined_df.Mine != joined_df.Compare].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mine</th>\n",
       "      <th>Compare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mine  Compare\n",
       "PassengerId               \n",
       "895             0        1\n",
       "898             1        0\n",
       "909             0        1\n",
       "919             0        1\n",
       "920             0        1\n",
       "924             0        1\n",
       "927             0        1\n",
       "933             0        1\n",
       "941             0        1\n",
       "967             1        0\n",
       "973             1        0\n",
       "979             0        1\n",
       "982             1        0\n",
       "990             0        1\n",
       "1000            0        1\n",
       "1005            1        0\n",
       "1022            0        1\n",
       "1036            0        1\n",
       "1040            0        1\n",
       "1049            0        1\n",
       "1050            0        1\n",
       "1051            1        0\n",
       "1055            0        1\n",
       "1073            1        0\n",
       "1079            0        1\n",
       "1094            1        0\n",
       "1109            1        0\n",
       "1115            0        1\n",
       "1126            1        0\n",
       "1128            1        0\n",
       "1129            0        1\n",
       "1134            1        0\n",
       "1144            1        0\n",
       "1200            1        0\n",
       "1203            0        1\n",
       "1208            1        0\n",
       "1225            1        0\n",
       "1228            0        1\n",
       "1237            0        1\n",
       "1255            0        1\n",
       "1259            1        0\n",
       "1261            0        1\n",
       "1268            1        0\n",
       "1275            1        0\n",
       "1297            0        1\n",
       "1299            1        0"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df[joined_df.Mine != joined_df.Compare]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
