{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "**Data preparation**\n",
    "\n",
    "- Handling missing values\n",
    "- Handling categorical features\n",
    "\n",
    "**Train & Tune Model**\n",
    "\n",
    "- Train model\n",
    "- Test accuracy\n",
    "- Tune model parameters\n",
    "\n",
    "**Make Prediction**\n",
    "- Update test data set\n",
    "- Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Data & Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the Titanic training data\n",
    "import pandas as pd\n",
    "path = '../data/'\n",
    "url = path + 'train.csv'\n",
    "titanic = pd.read_csv(url, index_col='PassengerId')\n",
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn models expect that all values are **numeric** and **hold meaning**. Thus, missing values are not allowed by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill missing values for Age with the median age\n",
    "titanic.Age.fillna(titanic.Age.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing values for Embarked with the mode\n",
    "titanic.Embarked.fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the Titanic test data\n",
    "import pandas as pd\n",
    "path = '../data/'\n",
    "url = path + 'test.csv'\n",
    "titanic_test = pd.read_csv(url)\n",
    "titanic_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "titanic_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test.Age.fillna(titanic_test.Age.median(), inplace=True)\n",
    "titanic_test.Fare.fillna(titanic_test.Fare.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Handling categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding (0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and encode Female feature\n",
    "titanic['Female'] = titanic.Sex.map({'male':0, 'female':1})\n",
    "titanic_test['Female'] = titanic_test.Sex.map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "embarked_dummies = pd.get_dummies(titanic.Embarked, prefix='Embarked')\n",
    "embarked_dummies.drop(embarked_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic = pd.concat([titanic, embarked_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "embarked_dummies = pd.get_dummies(titanic_test.Embarked, prefix='Embarked')\n",
    "embarked_dummies.drop(embarked_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic_test = pd.concat([titanic_test, embarked_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "pclass_dummies = pd.get_dummies(titanic.Pclass, prefix='Pclass')\n",
    "pclass_dummies.drop(pclass_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic = pd.concat([titanic, pclass_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of dummy variables for Embarked\n",
    "pclass_dummies = pd.get_dummies(titanic_test.Pclass, prefix='Pclass')\n",
    "pclass_dummies.drop(pclass_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame\n",
    "titanic_test = pd.concat([titanic_test, pclass_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine Sibling and Parent Columns\n",
    "titanic['Family'] =  titanic[\"Parch\"] + titanic[\"SibSp\"]\n",
    "titanic['Family'].loc[titanic['Family'] > 0] = 1\n",
    "titanic['Family'].loc[titanic['Family'] == 0] = 0\n",
    "\n",
    "titanic_test['Family'] =  titanic_test[\"Parch\"] + titanic_test[\"SibSp\"]\n",
    "titanic_test['Family'].loc[titanic_test['Family'] > 0] = 1\n",
    "titanic_test['Family'].loc[titanic_test['Family'] == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.drop(\"Cabin\",axis=1,inplace=True)\n",
    "titanic.drop(\"Name\",axis=1,inplace=True)\n",
    "titanic.drop(\"Sex\",axis=1,inplace=True)\n",
    "titanic.drop(\"Ticket\",axis=1,inplace=True)\n",
    "titanic.drop(\"Embarked\",axis=1,inplace=True)\n",
    "titanic.drop(\"Pclass\",axis=1,inplace=True)\n",
    "titanic.drop(\"Parch\",axis=1,inplace=True)\n",
    "titanic.drop(\"SibSp\",axis=1,inplace=True)\n",
    "\n",
    "titanic_test.drop(\"Cabin\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Name\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Sex\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Ticket\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Embarked\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Pclass\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"Parch\",axis=1,inplace=True)\n",
    "titanic_test.drop(\"SibSp\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 9 columns):\n",
      "Survived      891 non-null int64\n",
      "Age           891 non-null float64\n",
      "Fare          891 non-null float64\n",
      "Female        891 non-null int64\n",
      "Embarked_Q    891 non-null float64\n",
      "Embarked_S    891 non-null float64\n",
      "Pclass_2      891 non-null float64\n",
      "Pclass_3      891 non-null float64\n",
      "Family        891 non-null int64\n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 69.6 KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 9 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Age            418 non-null float64\n",
      "Fare           418 non-null float64\n",
      "Female         418 non-null int64\n",
      "Embarked_Q     418 non-null float64\n",
      "Embarked_S     418 non-null float64\n",
      "Pclass_2       418 non-null float64\n",
      "Pclass_3       418 non-null float64\n",
      "Family         418 non-null int64\n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 29.5 KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Train and Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978675645342\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define training and testing sets\n",
    "\n",
    "X_train = titanic.drop(\"Survived\",axis=1)\n",
    "y_train = titanic[\"Survived\"]\n",
    "X_test  = titanic_test.drop(\"PassengerId\",axis=1).copy()\n",
    "\n",
    "# import KNN class we need from scikit-learnQ\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate the estimator \n",
    "knn = KNeighborsClassifier(n_neighbors=2, weights='distance') # Tune these parameters!\n",
    "\n",
    "# run a knn.fit on the data to build the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "titanic['y_pred_class_knn']=knn.predict(X_train)\n",
    "\n",
    "# Test the accuracy\n",
    "print knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97979797979797978"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "random_forest.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Make Predictions\n",
    "\n",
    "## Update Test Dataset & Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make predictions for testing set\n",
    "titanic_test['Survived'] = random_forest.predict(X_test)\n",
    "\n",
    "\n",
    "path = '../data/'\n",
    "url = path + 'submit_randomforest.csv'\n",
    "titanic_test.index = titanic_test.PassengerId\n",
    "titanic_test.to_csv(columns = ['Survived'], path_or_buf = url, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: Survived, dtype: float64\n",
      "0    0.636364\n",
      "1    0.363636\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print titanic.Survived.value_counts() / titanic.Survived.count()\n",
    "print titanic_test.Survived.value_counts() / titanic_test.Survived.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 10)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "my_file = 'submit.csv'\n",
    "comp_file = 'OmarElGabry.csv' # Downloaded this file from Kaggle as a comparison.\n",
    "\n",
    "url = path + my_file\n",
    "my_df = pd.read_csv(url, index_col='PassengerId')\n",
    "\n",
    "url = path + comp_file\n",
    "comp_df = pd.read_csv(url, index_col='PassengerId')\n",
    "\n",
    "joined_df = pd.concat([my_df, comp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mine</th>\n",
       "      <th>Compare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mine  Compare\n",
       "PassengerId               \n",
       "892             0        0\n",
       "893             0        0\n",
       "894             0        0\n",
       "895             1        1\n",
       "896             1        0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.columns=['Mine', 'Compare']\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mine       44\n",
       "Compare    44\n",
       "dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df[joined_df.Mine != joined_df.Compare].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
